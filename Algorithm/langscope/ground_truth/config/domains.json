{
  "version": "1.0.0",
  "domains": {
    "asr": {
      "category": "multimodal",
      "name": "Automatic Speech Recognition",
      "description": "Convert audio to text",
      "input_modalities": ["audio"],
      "output_modality": "text",
      "evaluation_mode": "metrics_only",
      "primary_metric": "wer",
      "metrics": ["wer", "cer", "mer"],
      "languages": ["en", "hi", "bn", "ta", "te"],
      "stratification": ["language", "difficulty", "duration", "audio_quality"],
      "leaderboard_sort": "wer",
      "leaderboard_direction": "asc"
    },
    "tts": {
      "category": "multimodal",
      "name": "Text-to-Speech",
      "description": "Convert text to natural speech",
      "input_modalities": ["text"],
      "output_modality": "audio",
      "evaluation_mode": "hybrid",
      "primary_metric": "composite_tts",
      "metrics": ["round_trip_wer", "utmos", "snr", "speaker_similarity", "composite_tts"],
      "languages": ["en", "hi"],
      "stratification": ["language", "difficulty", "style"],
      "leaderboard_sort": "composite_tts",
      "leaderboard_direction": "desc"
    },
    "visual_qa": {
      "category": "multimodal",
      "name": "Visual Question Answering",
      "description": "Answer questions about images",
      "input_modalities": ["image", "text"],
      "output_modality": "text",
      "evaluation_mode": "hybrid",
      "primary_metric": "accuracy",
      "metrics": ["exact_match", "contains", "semantic_match", "accuracy"],
      "stratification": ["difficulty", "question_type"],
      "leaderboard_sort": "accuracy",
      "leaderboard_direction": "desc"
    },
    "document_extraction": {
      "category": "multimodal",
      "name": "Document Extraction",
      "description": "Extract structured data from documents",
      "input_modalities": ["image", "document"],
      "output_modality": "json",
      "evaluation_mode": "metrics_only",
      "primary_metric": "field_accuracy",
      "metrics": ["field_accuracy", "field_precision", "field_recall", "critical_accuracy", "schema_valid"],
      "stratification": ["difficulty", "document_type"],
      "leaderboard_sort": "field_accuracy",
      "leaderboard_direction": "desc"
    },
    "image_captioning": {
      "category": "multimodal",
      "name": "Image Captioning",
      "description": "Generate captions for images",
      "input_modalities": ["image"],
      "output_modality": "text",
      "evaluation_mode": "metrics_only",
      "primary_metric": "cider",
      "metrics": ["bleu", "rouge_l", "cider", "meteor"],
      "stratification": ["difficulty"],
      "leaderboard_sort": "cider",
      "leaderboard_direction": "desc"
    },
    "ocr": {
      "category": "multimodal",
      "name": "Optical Character Recognition",
      "description": "Extract text from images",
      "input_modalities": ["image"],
      "output_modality": "text",
      "evaluation_mode": "metrics_only",
      "primary_metric": "cer",
      "metrics": ["cer", "wer", "line_accuracy"],
      "stratification": ["difficulty", "language"],
      "leaderboard_sort": "cer",
      "leaderboard_direction": "asc"
    },
    "needle_in_haystack": {
      "category": "long_context",
      "name": "Needle in Haystack",
      "description": "Retrieve hidden facts from long context",
      "input_modalities": ["text"],
      "output_modality": "text",
      "evaluation_mode": "metrics_only",
      "primary_metric": "retrieval_accuracy",
      "metrics": ["retrieval_accuracy", "contains", "exact_match"],
      "stratification": ["context_length", "needle_position", "needle_type"],
      "leaderboard_sort": "retrieval_accuracy",
      "leaderboard_direction": "desc",
      "context_lengths": [4096, 8192, 16384, 32768, 65536, 131072]
    },
    "long_document_qa": {
      "category": "long_context",
      "name": "Long Document QA",
      "description": "Answer questions about long documents",
      "input_modalities": ["text"],
      "output_modality": "text",
      "evaluation_mode": "hybrid",
      "primary_metric": "accuracy",
      "metrics": ["exact_match", "f1", "accuracy", "evidence_recall"],
      "stratification": ["difficulty", "context_length", "document_type"],
      "leaderboard_sort": "accuracy",
      "leaderboard_direction": "desc"
    },
    "multi_document_reasoning": {
      "category": "long_context",
      "name": "Multi-Document Reasoning",
      "description": "Answer questions requiring multiple documents",
      "input_modalities": ["text"],
      "output_modality": "text",
      "evaluation_mode": "hybrid",
      "primary_metric": "answer_accuracy",
      "metrics": ["answer_accuracy", "evidence_accuracy", "reasoning_accuracy"],
      "stratification": ["difficulty", "document_count"],
      "leaderboard_sort": "answer_accuracy",
      "leaderboard_direction": "desc"
    },
    "code_completion": {
      "category": "long_context",
      "name": "Code Completion",
      "description": "Complete code given context",
      "input_modalities": ["text"],
      "output_modality": "code",
      "evaluation_mode": "metrics_only",
      "primary_metric": "tests_pass",
      "metrics": ["syntax_valid", "tests_pass", "exact_match", "bleu"],
      "languages": ["python", "javascript", "typescript"],
      "stratification": ["difficulty", "language", "context_length"],
      "leaderboard_sort": "tests_pass",
      "leaderboard_direction": "desc"
    },
    "long_summarization": {
      "category": "long_context",
      "name": "Long Summarization",
      "description": "Summarize long documents",
      "input_modalities": ["text"],
      "output_modality": "text",
      "evaluation_mode": "hybrid",
      "primary_metric": "rouge_l",
      "metrics": ["rouge_1", "rouge_2", "rouge_l", "factual_consistency", "coverage"],
      "stratification": ["difficulty", "context_length"],
      "leaderboard_sort": "rouge_l",
      "leaderboard_direction": "desc"
    }
  }
}


